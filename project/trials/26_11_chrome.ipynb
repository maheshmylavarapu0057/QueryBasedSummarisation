{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "26_11_chrome.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohRTU3p5oU9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeab6f4a-e792-4673-f204-962ea874ba17"
      },
      "source": [
        "!pip uninstall spacy\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling spacy-2.2.4:\n",
            "  Would remove:\n",
            "    /usr/local/bin/spacy\n",
            "    /usr/local/lib/python3.6/dist-packages/bin/*\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy-2.2.4.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/*\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.6/dist-packages/bin/theano_cache.py\n",
            "    /usr/local/lib/python3.6/dist-packages/bin/theano_nose.py\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled spacy-2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CFwQhewfPK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b4200e-6bb5-4b98-8aef-6ddf60541a4e"
      },
      "source": [
        "!pip install spacy\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/b2/12466d3018bb84b039139ef76436ea7a01e98125c2aee6a81e527eb4ebe1/spacy-2.3.4-cp36-cp36m-manylinux2014_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/c9/ce2e03720a5647fd90da575325376ff258653a05f357aa970fd87e6c1a55/thinc-7.4.3-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 51.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n",
            "Installing collected packages: thinc, spacy\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "Successfully installed spacy-2.3.4 thinc-7.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOdyu72nAtCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dc5e192-96fd-48bb-88b1-7b863348d617"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "from collections import defaultdict\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "import torchtext\n",
        "from torchtext.data import Field, Dataset, Example\n",
        "from nltk.translate.bleu_score import sentence_bleu,SmoothingFunction\n",
        "import spacy\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb3CHZThivlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d7f1341-6b1e-4c35-f2d2-3c1f9bbe6ab8"
      },
      "source": [
        "!python -m spacy download xx_ent_wiki_sm\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xx_ent_wiki_sm==2.3.0 from https://github.com/explosion/spacy-models/releases/download/xx_ent_wiki_sm-2.3.0/xx_ent_wiki_sm-2.3.0.tar.gz#egg=xx_ent_wiki_sm==2.3.0 in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from xx_ent_wiki_sm==2.3.0) (2.3.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (1.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (50.3.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (0.8.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (1.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (0.4.1)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (7.4.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (2.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->xx_ent_wiki_sm==2.3.0) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('xx_ent_wiki_sm')\n",
            "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.3.1) (2.3.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (50.3.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SLd4AtJlddp"
      },
      "source": [
        "en = spacy.load('en_core_web_sm')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTZIugWsY85d"
      },
      "source": [
        "contractions = { \n",
        "\"i ain't\": \"i am not\",\n",
        "\"ain't that\": \"is not that\",\n",
        "\"ain't she\": \"is not she\",\n",
        "\"ain't it\": \"is not it\",\n",
        "\"it ain't\": \"it is not\",\n",
        "\"that ain't\": \"that is not\",\n",
        "\"this ain't\": \"this is not\",\n",
        "\"ain't you\": \"are not you\",\n",
        "\"aren't\": \"you are\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he would\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"I'd\": \"I would\",\n",
        "\"I'll\": \"I will\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"needn't\": \"need not\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"she'd\": \"she would\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that's\": \"that is\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we would\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when is\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who's\": \"who is\",\n",
        "\"why's\": \"why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"y'all\": \"you all\",\n",
        "\"you'd\": \"you would\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "\n",
        "}\n",
        "\n",
        "contractions2 = {\n",
        "    \"'s\": \" is\",\n",
        "    \"ain't\" : \" is not\",\n",
        "    \"'ve\": \"have\",\n",
        "    \"'d\": \"would\",\n",
        "    \"'ll\": \"will\"\n",
        "}\n",
        "\n"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGtcsdjAFJt9"
      },
      "source": [
        "learning_rate= 0.0004\n",
        "hidden_size = 256\n",
        "emb_size = 300"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe7q9idWlX2H"
      },
      "source": [
        "def preprocess_en (X) :\n",
        "    for k,v in contractions.items():\n",
        "        X = X.lower().replace(k,v)\n",
        "    for k,v in contractions2.items():\n",
        "        X = X.lower().replace(k,v)\n",
        "    X = X.strip().split('\\n')\n",
        "    #X = [re.sub(r'[^\\w\\s]', '', xx) for xx in X]\n",
        "    return X \n",
        "    \n",
        "\n",
        "def preprocess_hi (X) :\n",
        "    for k,v in contractions_hin.items():\n",
        "        X = X.replace(k,v)\n",
        "    X = X.strip().split('\\n')\n",
        "    return X\n",
        "\n",
        "def preprocess2(X):\n",
        "    cont={\n",
        "    \"<eos>\":\"\",\n",
        "    \"<s>\":\" \"\n",
        "    }\n",
        "    for k,v in cont.items():\n",
        "      X=X.replace(k,v)\n",
        "    return X"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp4LOI3I0dEj"
      },
      "source": [
        "def create_dictionary(X) :\n",
        "    word_freq = defaultdict(int)\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        X[i] = [w for w in X[i] if w!=''] \n",
        "        for word in X[i] :\n",
        "            word_freq[word] += 1\n",
        "\n",
        "    word_i = {\"<sos>\": 0, \"<eos>\": 1}\n",
        "    i_word = {0: \"<sos>\", 1: \"<eos>\"}\n",
        "    wid = 2\n",
        "    for w,c in word_freq.items():\n",
        "        word_i[w] = wid \n",
        "        i_word[wid] = w\n",
        "        wid += 1\n",
        "    return wid,word_i,i_word"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9m3gK0sYvAw"
      },
      "source": [
        "def reverse_en(x) :\n",
        "    words = x.split()\n",
        "    words = list(reversed(words))\n",
        "    words = (\" \".join(words))\n",
        "    return words"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k78_VH4zxg2v"
      },
      "source": [
        "def delete_min(query,document,summary):\n",
        "  query = [xx.split(\" \") for xx in query]\n",
        "  summary=[xx.split(\" \") for xx in summary]\n",
        "  document=[xx.split(\" \") for xx in document]\n",
        "  for i in range(len(query)) :\n",
        "    if (len(query[i]) and len(summary[i])) :\n",
        "        continue\n",
        "    else :\n",
        "        del query[i]\n",
        "        del summary[i]\n",
        "        del document[i]\n",
        "\n",
        "  return query,document,summary"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSNbuWNzyY5S"
      },
      "source": [
        "def summary_creation(reference_list,query,document,summary):\n",
        "  for i in  range(len(query)):\n",
        "    query[i]=query[i].strip()\n",
        "    if query[i] in reference_lists.keys():\n",
        "      reference_lists[query[i]].append(summary[i])\n",
        "    else:\n",
        "      reference_lists[query[i]]=[]\n",
        "      reference_lists[query[i]].append(summary[i])\n",
        "    \n",
        "  return reference_lists"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXxJa7uvJhM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1652a6a7-83d6-4caf-8ea8-bdc526a22676"
      },
      "source": [
        "\n",
        "\n",
        "train_query=open('/content/drive/MyDrive/data/train_query').read()\n",
        "test_query=open('/content/drive/MyDrive/data/test_query').read()\n",
        "val_query=open('/content/drive/MyDrive/data/valid_query').read()\n",
        "\n",
        "\n",
        "\n",
        "train_content=open('/content/drive/MyDrive/data/train_content').read()\n",
        "test_content=open('/content/drive/MyDrive/data/test_content').read()\n",
        "val_content=open('/content/drive/MyDrive/data/valid_content').read()\n",
        "\n",
        "\n",
        "train_summary=open('/content/drive/MyDrive/data/train_summary').read()\n",
        "test_summary=open('/content/drive/MyDrive/data/test_summary').read()\n",
        "val_summary=open('/content/drive/MyDrive/data/valid_summary').read()\n",
        "\n",
        "\n",
        "\n",
        "train_query=preprocess_en(train_query)\n",
        "train_content=preprocess_en(train_content)\n",
        "train_summary=preprocess_en(train_summary)\n",
        "\n",
        "\n",
        "test_query=preprocess_en(test_query)\n",
        "test_content=preprocess_en(test_content)\n",
        "test_summary=preprocess_en(test_summary)\n",
        "\n",
        "val_query=preprocess_en(val_query)\n",
        "val_content=preprocess_en(val_content)\n",
        "val_summary=preprocess_en(val_summary)\n",
        "#y_raw = preprocess_en(y_raw)\n",
        "\n",
        "reference_lists={}\n",
        "# reference_lists[query[0]]=summary[0]\n",
        "sum=0\n",
        "total_queries=[]\n",
        "\n",
        "\n",
        "refermcer_lists=summary_creation(reference_lists,train_query,train_content,train_summary)\n",
        "reference_lists=summary_creation(reference_lists,test_query,test_content,test_summary)\n",
        "reference_lists=summary_creation(reference_lists,val_query,val_content,val_summary)\n",
        "print(test_query[220])\n",
        "train_query,train_content,train_summary=delete_min(train_query,train_content,train_summary)\n",
        "test_query,test_content,test_summary=delete_min(test_query,test_content,test_summary)\n",
        "val_query,val_content,val_summary=delete_min(val_query,val_content,val_summary)\n"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s> abstinence message : is the abstinence-only message appropriate ? <eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL2vULUt00zX"
      },
      "source": [
        "def tokenize_en(text):\n",
        "  ret = [tok.text for tok in en.tokenizer(str(text))]\n",
        "  return ret\n",
        "def tokenize_hin(text):\n",
        "  ret = [tok.text for tok in hin.tokenizer(str(text))]\n",
        "  return ret"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS4HgFAdA4zT"
      },
      "source": [
        "TEXT_en = torchtext.data.Field(\n",
        "  tokenize    = tokenize_en,\n",
        "  lower       = True,\n",
        "  init_token  = '<sos>',\n",
        "  eos_token   = '<eos>'\n",
        ")\n",
        "TEXT_hin = torchtext.data.Field(\n",
        "  tokenize    = tokenize_hin,\n",
        "  lower       = True,\n",
        "  init_token  = '<sos>',\n",
        "  eos_token   = '<eos>'\n",
        ")"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC7ilpDM5yhN"
      },
      "source": [
        "fields = [('query',TEXT_en),('document',TEXT_en),('summary',TEXT_en)]\n",
        "def fun_bucket(query,content,summary): \n",
        "  examples = []\n",
        "  for i in range(len(query)):\n",
        "    temp = Example.fromlist([query[i],content[i],summary[i]],fields=fields)\n",
        "    examples.append(temp)\n",
        "  return examples"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na2HZZt3AsxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2562da-42b9-4d1c-8c6c-1f8bddf39887"
      },
      "source": [
        "train_check = torchtext.data.Dataset(fun_bucket(train_query,train_content,train_summary),fields)\n",
        "test_check=torchtext.data.Dataset(fun_bucket(test_query,test_content,test_summary),fields)\n",
        "val_check=torchtext.data.Dataset(fun_bucket(val_query,val_content,val_summary),fields)\n",
        "print(train_check[0])"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torchtext.data.example.Example object at 0x7f27ee654588>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbSTGboy1dU4"
      },
      "source": [
        "batch_size = 8\n",
        "\n",
        "train_iterator = torchtext.data.BucketIterator(\n",
        "    train_check,batch_size,sort_within_batch=False,device=device,repeat=False,sort_key=False\n",
        ")\n",
        "test_iterator = torchtext.data.BucketIterator(\n",
        "    test_check,batch_size,sort_within_batch=False,device=device,repeat=False,sort_key=False\n",
        ")\n",
        "val_iterator = torchtext.data.BucketIterator(\n",
        "    val_check,batch_size,sort_within_batch=False,device=device,repeat=False,sort_key=False\n",
        ")"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57JHKQMK-GYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5583ab54-b112-4c38-8bfe-3c17d24f9129"
      },
      "source": [
        "TEXT_en.build_vocab(train_check,test_check,val_check)\n",
        "print(TEXT_en.vocab)\n",
        "#TEXT_hin.build_vocab(train_check,test_check)\n"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torchtext.vocab.Vocab object at 0x7f27ee654978>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnodaDK0-GCf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca92bc68-336c-4587-8de2-d6d01c35bade"
      },
      "source": [
        "vocab_en = TEXT_en.vocab \n",
        "print(vocab_en)\n",
        "#vocab_hin = TEXT_hin.vocab\n",
        "print(len(vocab_en.stoi))\n",
        "src_vocab_size = len(vocab_en.stoi)\n",
        "trg_vocab_size=len(vocab_en.stoi)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torchtext.vocab.Vocab object at 0x7f27ee654978>\n",
            "29253\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnjCi1KEkZ3p"
      },
      "source": [
        "# Encoder RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJQhvS2AkYGm"
      },
      "source": [
        "class query_encoderRNN(nn.Module):\n",
        "\n",
        "  def __init__(self,input_size,emb_size,hidden_size,layers=1):\n",
        "    super(query_encoderRNN,self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.n_layers = layers\n",
        "    self.embedding = nn.Embedding(input_size,emb_size)\n",
        "    self.rnn = nn.GRU(emb_size,hidden_size,num_layers=4,bidirectional=True)\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "  \n",
        "  def forward(self,input):\n",
        "    embedding = self.dropout(self.embedding(input))\n",
        "    outputs,hidden = self.rnn(embedding)\n",
        "    hidden=hidden[3]\n",
        "    hidden=hidden.unsqueeze(1)\n",
        "    \n",
        "    hidden=hidden.permute(1,0,2)\n",
        "    #print(hidden.shape)\n",
        "    return outputs,hidden\n"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC4wf1w1wLeA"
      },
      "source": [
        "class document_encoderRNN(nn.Module):\n",
        "\n",
        "  def __init__(self,input_size,emb_size,hidden_size,layers=1):\n",
        "    super(document_encoderRNN,self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.n_layers = layers\n",
        "    self.embedding = nn.Embedding(input_size,emb_size)\n",
        "    self.rnn = nn.GRU(emb_size,hidden_size,num_layers=4,bidirectional=True)\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "  \n",
        "  \n",
        "  def forward(self,input,query_encoder):\n",
        "    embedding = self.dropout(query_encoder.embedding(input))\n",
        "    outputs,hidden = self.rnn(embedding)\n",
        "    \n",
        "    hidden=torch.cat((hidden[3],hidden[2]),1)\n",
        "    print(hidden.shape,\"docu\")\n",
        "    hidden=hidden.unsqueeze(1)\n",
        "    hidden=hidden.permute(1,0,2)\n",
        "    print(\"encoder\",hidden.shape,outputs.shape)\n",
        "    return outputs,hidden\n"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x11oM0qpkkBJ"
      },
      "source": [
        "class decoderRNN(nn.Module):\n",
        "    def __init__(self, output_size, embedding_size, hidden_size):\n",
        "        super(decoderRNN, self).__init__()\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "        self.hidden_size =hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.embedding_size = embedding_size\n",
        "        \n",
        "        self.gru = nn.GRU(self.embedding_size + self.hidden_size*2, self.hidden_size,batch_first=True,num_layers=4,bidirectional=True)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.hidden_size =2* hidden_size\n",
        "        # used for attention\n",
        "        self.fc = nn.Linear(self.hidden_size, self.output_size) \n",
        "        self.Wq = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.Wd = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.Uq = nn.Linear(self.hidden_size*2,self.hidden_size)\n",
        "        self.Ud = nn.Linear(self.hidden_size*2,self.hidden_size)\n",
        "        self.Vq = nn.Linear(self.hidden_size, 1)\n",
        "        self.Vd = nn.Linear(self.hidden_size,1)\n",
        "        self.Z  = nn.Linear(self.hidden_size*2,self.hidden_size)\n",
        "        self.Wdec=nn.Linear(self.hidden_size,self.hidden_size)\n",
        "        self.Vdec=nn.Linear(self.hidden_size,self.hidden_size)\n",
        "        self.Wo=nn.Linear(self.hidden_size,trg_vocab_size)\n",
        "    def forward(self,yt_,dt_,hq,hd,query_encoder):\n",
        "        #print(dt_.shape)\n",
        "        dt_=dt_.permute(1,0,2)\n",
        "        hq = hq.permute(1,0,2)\n",
        "        hd = hd.permute(1,0,2)\n",
        "        print(\"gh\")\n",
        "        yt_=query_encoder.embedding(yt_).unsqueeze(1)\n",
        "        #print(yt_.shape,dt_.shape)\n",
        "        x = torch.cat((yt_,dt_), -1)\n",
        "       \n",
        "        output, st = self.gru(x)\n",
        "        output =  output.view(-1, output.size(2))\n",
        "        yt = self.fc(output)\n",
        "        st=st[3]\n",
        "        st=st.unsqueeze(1)\n",
        "        score = torch.tanh(self.Wq(st) + self.Uq(hq))\n",
        "        attention_weights = torch.softmax(self.Vq(score), dim=1)\n",
        "        context_vector = attention_weights * hq\n",
        "        qt = torch.sum(context_vector, dim=1)\n",
        "        qt=qt.unsqueeze(1)\n",
        "       \n",
        "        score = torch.tanh(self.Wd(st) + self.Ud(hd)+self.Z(qt))\n",
        "        attention_weights = torch.softmax(self.Vd(score), dim=1)\n",
        "        context_vector = attention_weights * hd\n",
        "        dt = torch.sum(context_vector, dim=1)\n",
        "        #yt=torch.softmax(self.Wo(self.Wdec(st).squeeze() + self.Vdec(dt)),dim=1)\n",
        "        dt=dt.unsqueeze(1)\n",
        "        dt=dt.permute(1,0,2)\n",
        "        #yt=yt.argmax(1)\n",
        "        #print(\"hello,\",yt.shape)\n",
        "        #zt=torch.sum(yt,dim=1)\n",
        "        print(dt.shape)\n",
        "        #return yt, dt, attention_weights"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM3zDJvl1d4D"
      },
      "source": [
        "t_f_c = 0.5\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self,query_encoder,document_encoder,decoder,device):\n",
        "    super(Seq2Seq,self).__init__()\n",
        "    self.query_encoder = query_encoder\n",
        "    self.document_encoder = document_encoder\n",
        "    self.decoder=decoder\n",
        "    self.device = device\n",
        "  \n",
        "  def forward(self,query_source,document_source,target,teaching = 0.5):\n",
        "    \n",
        "    target_length = target.shape[0]\n",
        "    batch_size = target.shape[1]\n",
        "    outputs = torch.zeros(target_length,batch_size,trg_vocab_size).to(self.device)\n",
        "    query_encoder_outputs,query_hidden = self.query_encoder(query_source)\n",
        "    document_encoder_outputs,document_hidden=self.document_encoder(document_source,self.query_encoder)\n",
        "    input = target[0,:]\n",
        "    wts = []\n",
        "    \n",
        "    hidden=document_hidden\n",
        "    print(hidden.shape)\n",
        "    for i in range(1,target_length):\n",
        "      output , hidden,_ = self.decoder(input,hidden,query_encoder_outputs,document_encoder_outputs,self.query_encoder)\n",
        "      #print(output.shape)\n",
        "      outputs[i]=output\n",
        "      top1 = output.argmax(1)\n",
        "      input = top1 if random.random()<t_f_c else target[i]\n",
        "      wts.append(_)\n",
        "    #print(outputs.shape)\n",
        "    return outputs, wts\n"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psoGp9rW1ZTu"
      },
      "source": [
        "dropout = 0.5\n",
        "query_encoder = query_encoderRNN(len(vocab_en),emb_size, hidden_size).to(device)\n",
        "document_encoder=document_encoderRNN(len(vocab_en),emb_size,hidden_size).to(device)\n",
        "decoder = decoderRNN(len(vocab_en),emb_size,hidden_size).to(device)\n",
        "\n",
        "model = Seq2Seq(query_encoder,document_encoder,decoder,device).to(device)"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmMTVCVH0tna"
      },
      "source": [
        "def train(model,iterator,query_encoder_optimizer,document_encoder_optimizer,decoder_optimizer,criterion,clip=1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for i,batch in enumerate(iterator):\n",
        "        query_source = batch.query\n",
        "        document_source=batch.document\n",
        "        target = batch.summary\n",
        "        query_encoder_optimizer.zero_grad()\n",
        "        document_encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        output,_ = model(query_source ,document_source,target)\n",
        "        \n",
        "        output_dimension = output.shape[-1]\n",
        "      \n",
        "        output = output[1:].view(-1 ,output_dimension).to(device)\n",
        "        target = target[1:].view(-1).to(device)\n",
        "        #print(\"hi \",output.shape,target.shape)\n",
        "        #print(\"namasete\")\n",
        "        loss = criterion(output,target)\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        query_encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "        document_encoder_optimizer.step()\n",
        "        total_loss +=loss.item()\n",
        "    return total_loss/len(iterator)\n"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_REWYwJ08p4"
      },
      "source": [
        "\n",
        "def evaluate(model,iterator,criterion):\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for i,batch in enumerate(iterator):\n",
        "      query_source = batch.query\n",
        "      document_source=batch.document\n",
        "      target = batch.summary\n",
        "      #print(query_source,document_source,target)\n",
        "      output,_ = model(query_source,document_source,target,0)\n",
        "      output_dim = output.shape[-1]\n",
        "      output = output[1:].view(-1, output_dim).to(device)\n",
        "\n",
        "      target = target[1:].view(-1).to(device)\n",
        "      \n",
        "      loss = criterion(output,target)\n",
        "      epoch_loss+=loss.item()\n",
        "  return epoch_loss/len(iterator)\n"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7MMgKfL36yE"
      },
      "source": [
        "import time\n",
        "EPOCH = 1\n",
        "timr = []\n",
        "train_loss_list = [] \n",
        "test_loss_list = []\n",
        "learning_rate =  0.0004"
      ],
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOKapU9hoFj5"
      },
      "source": [
        "query_encoder_optimizer = optim.SGD(query_encoder.parameters(), lr=learning_rate)\n",
        "document_encoder_optimizer=optim.SGD(document_encoder.parameters(),lr=learning_rate)\n",
        "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = 0)"
      ],
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMRZX18fOQZo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "739993ae-899a-4a93-e53d-40371770aee1"
      },
      "source": [
        "\n",
        "EPOCH = 50\n",
        "for epoch in range(EPOCH):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model,train_iterator,query_encoder_optimizer,document_encoder_optimizer,decoder_optimizer,criterion)\n",
        "    test_loss = evaluate(model,val_iterator,criterion)\n",
        "    test_rouge()\n",
        "    PATH = '/content/drive/My Drive/baseline'\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "    model = Seq2Seq(query_encoder,document_encoder,decoder,device).to(device)\n",
        "    model.load_state_dict(torch.load('/content/drive/My Drive/baseline'))\n",
        "    end_time = time.time()\n",
        "    train_loss_list.append(train_loss)\n",
        "    test_loss_list.append(test_loss)\n",
        "    timr.append(end_time-start_time)\n",
        "    print(epoch,train_loss,test_loss)\n",
        "\n"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 512]) docu\n",
            "encoder torch.Size([1, 8, 512]) torch.Size([140, 8, 512])\n",
            "torch.Size([1, 8, 512])\n",
            "gh\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-254-a89c2d78f35a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquery_encoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument_encoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtest_rouge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-250-258f9e0b1113>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, query_encoder_optimizer, document_encoder_optimizer, decoder_optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_source\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mdocument_source\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutput_dimension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-248-12780354ef15>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query_source, document_source, target, teaching)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquery_encoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument_encoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_encoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0;31m#print(output.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-247-292ac873fa23>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, yt_, dt_, hq, hd, query_encoder)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mcontext_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYYMr89es-yS"
      },
      "source": [
        "'''\n",
        "EPOCH = 200\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model,train_iterator,query_encoder_optimizer,document_encoder_optimizer,decoder_optimizer,criterion)\n",
        "    test_loss = evaluate(model,test_iterator,criterion)\n",
        "    end_time = time.time()\n",
        "    train_loss_list.append(train_loss)\n",
        "    test_loss_list.append(test_loss)\n",
        "    timr.append(end_time-start_time)\n",
        "    print(epoch,train_loss,test_loss)\n",
        "  '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXrT5UMvQy76"
      },
      "source": [
        "'''\n",
        "EPOCH = 300\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model,train_iterator,query_encoder_optimizer,document_encoder_optimizer,decoder_optimizer,criterion)\n",
        "    test_loss = evaluate(model,test_iterator,criterion)\n",
        "    end_time = time.time()\n",
        "    train_loss_list.append(train_loss)\n",
        "    test_loss_list.append(test_loss)\n",
        "    timr.append(end_time-start_time)\n",
        "    print(epoch,train_loss,test_loss)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOsCbhBwAZiQ"
      },
      "source": [
        "print(summary[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_wzzYWWxGyd"
      },
      "source": [
        "  # TOTAL TESTING  CODE\n",
        "def test_rouge():\n",
        "  model = Seq2Seq(query_encoder,document_encoder,decoder,device).to(device)\n",
        "  model.load_state_dict(torch.load('/content/drive/My Drive/baseline'))\n",
        "  model.eval()\n",
        "  !pip install rouge/requirements.txt\n",
        "  !pip install rouge-score\n",
        "  from rouge_score import rouge_scorer\n",
        "  results = []\n",
        "  rouge1=0\n",
        "  rouge2=0\n",
        "  rougel=0\n",
        "  c=0\n",
        "  results_query = []\n",
        "  results_pred = []\n",
        "  results_actual_summary = []\n",
        "  results_document = []\n",
        "  with torch.no_grad():\n",
        "    for j,batch in enumerate(test_iterator):\n",
        "      query_source = batch.query\n",
        "      document_source=batch.document\n",
        "      target = batch.summary\n",
        "      output,bat_wts = model(query_source,document_source,target,1)\n",
        "      output_dim = output.shape[0]\n",
        "      output = output.permute(1,0,2)\n",
        "      wts = []\n",
        "      for i in range(1,target.shape[0]):\n",
        "          l1 = [[p.item() for p in t] for t in bat_wts[i-1]]\n",
        "          l2 = [[row[i] for row in l1] for i in range(len(l1[0]))]\n",
        "          #print(l2)\n",
        "          wts.append(l2)\n",
        "      attn_wts = np.array(wts).T\n",
        "\n",
        "      for t in range(query_source.shape[1]):\n",
        "\n",
        "        target_pred = \"\"\n",
        "        target_actual = \"\"\n",
        "        query_actual = \"\"\n",
        "        document_actual=\"\"\n",
        "        actual = []\n",
        "        pred = []\n",
        "        for i in range(query_source.shape[0]):\n",
        "          query_actual += vocab_en.itos[query_source[i,t]]+\" \"\n",
        "        query_actual = query_actual.replace('<pad>','').replace('<sos>','').replace('<eos>','').strip()\n",
        "        temp = query_actual.split()\n",
        "        query_actual = ' '.join([str(elem) for elem in temp])\n",
        "        for i in range(document_source.shape[0]):\n",
        "          document_actual += vocab_en.itos[document_source[i,t]]+\" \"\n",
        "        document_actual = document_actual.replace('<pad>','').replace('<sos>','<s>').strip()\n",
        "        temp = document_actual.split()\n",
        "        document_actual = ' '.join([str(elem) for elem in temp])\n",
        "        \n",
        "        for i in range(1,target.shape[0]):\n",
        "          target_actual += vocab_en.itos[target[i,t]]+\" \"\n",
        "\n",
        "        target_actual = target_actual.replace('<pad>','').replace('<sos>','').replace('<eos>','').strip()\n",
        "        output_temp = output[t]\n",
        "        for i in range(1,target.shape[0]):\n",
        "          ind = output_temp.argmax(1)[i].item()\n",
        "          target_pred += vocab_en.itos[ind]+\" \"\n",
        "          \n",
        "          if ind == 1 :\n",
        "            break\n",
        "        \n",
        "        #results_attn_wts.append(attn_wts[t][:,0:i])\n",
        "        target_pred = target_pred.replace('<pad>','').replace('<sos>','<s>').strip()\n",
        "        query_actual=query_actual+' '+'<eos>'\n",
        "        query_actual=query_actual.strip()\n",
        "        \n",
        "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL','rouge2'], use_stemmer=True)\n",
        "        #print(query_actual)\n",
        "        r1_score=0\n",
        "        r2_score=0\n",
        "        rl_score=0\n",
        "        if query_actual  in reference_lists.keys():\n",
        "          for i in reference_lists[query_actual]:\n",
        "            scores=scorer.score(i,target_pred)\n",
        "            r1_score=max(r1_score,scores['rouge1'].fmeasure)\n",
        "            r2_score=max(r2_score,scores['rouge2'].fmeasure)\n",
        "            rl_score=max(rl_score,scores['rougeL'].fmeasure)\n",
        "            c=c+1\n",
        "            #print(scores)\n",
        "          rouge1=rouge1+r1_score\n",
        "          rouge2=rouge2+r2_score\n",
        "          rougel=rougel+rl_score\n",
        "\n",
        "        results_query.append(query_actual)\n",
        "        results_document.append(document_actual)\n",
        "        results_actual_summary.append(target_actual)\n",
        "        results_pred.append(target_pred)\n",
        "        print(\"rouge1\",rouge1/967)\n",
        "        print(\"rouge2\",rouge2/967)\n",
        "        print(\"rougel\",rougel/967)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkcEnQ0D4nFi"
      },
      "source": [
        "print(rouge1,rouge2,rougel,c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoBUywSgBX23"
      },
      "source": [
        "print(rouge1/(len(test_iterator)*batch_size))\n",
        "print(rouge2/(len(test_iterator)*batch_size))\n",
        "print(rougel/(len(test_iterator)*batch_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKYIio66SFTZ"
      },
      "source": [
        "PATH = '/content/drive/My Drive/baseline'\n",
        "torch.save(model.state_dict(), PATH)\n",
        "import pickle\n",
        " \n",
        "favorite_color = { \"lion\": vocab_en} \n",
        "pickle.dump( favorite_color, open( \"/content/drive/My Drive/baseline_dict\", \"wb\" ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA1mqYpb2eQG"
      },
      "source": [
        "print(test_loss_list)\n",
        "print(train_loss_list)\n",
        "print(len(train_loss_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s6XioHrqjSE"
      },
      "source": [
        "filename = '/content/drive/My Drive/results_baseline_update123.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9e5sx87rBl9"
      },
      "source": [
        "import csv  \n",
        "    \n",
        "# field names  \n",
        "names = ['Query', 'Actual_Summary','Predicted_Summary']  \n",
        "    \n",
        "# data rows of csv file  \n",
        "rows = list(zip(results_query,  results_actual_summary,results_pred))\n",
        "    \n",
        "# writing to csv file  \n",
        "with open(filename, 'w') as csvfile:  \n",
        "    # creating a csv writer object  \n",
        "    csvwriter = csv.writer(csvfile)  \n",
        "        \n",
        "    # writing the fields  \n",
        "    csvwriter.writerow(names)\n",
        "        \n",
        "    # writing the data rows  \n",
        "    csvwriter.writerows(rows) \n",
        "print(\"hi\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}